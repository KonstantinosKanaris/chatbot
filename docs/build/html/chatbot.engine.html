<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>chatbot.engine package &mdash; chatbot  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            chatbot
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">chatbot.engine package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-chatbot.engine.evaluator">chatbot.engine.evaluator module</a><ul>
<li><a class="reference internal" href="#chatbot.engine.evaluator.Evaluator"><code class="docutils literal notranslate"><span class="pre">Evaluator</span></code></a><ul>
<li><a class="reference internal" href="#chatbot.engine.evaluator.Evaluator.chat"><code class="docutils literal notranslate"><span class="pre">Evaluator.chat()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.evaluator.Evaluator.evaluate"><code class="docutils literal notranslate"><span class="pre">Evaluator.evaluate()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-chatbot.engine.trainer">chatbot.engine.trainer module</a><ul>
<li><a class="reference internal" href="#chatbot.engine.trainer.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul>
<li><a class="reference internal" href="#chatbot.engine.trainer.Trainer.batched_bleu_score"><code class="docutils literal notranslate"><span class="pre">Trainer.batched_bleu_score()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.trainer.Trainer.compute_metrics"><code class="docutils literal notranslate"><span class="pre">Trainer.compute_metrics()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.trainer.Trainer.train"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-chatbot.engine.utils">chatbot.engine.utils module</a><ul>
<li><a class="reference internal" href="#chatbot.engine.utils.EarlyStopping"><code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.utils.Timer"><code class="docutils literal notranslate"><span class="pre">Timer</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.utils.generate_batches"><code class="docutils literal notranslate"><span class="pre">generate_batches()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.utils.inverse_sigmoid_decay"><code class="docutils literal notranslate"><span class="pre">inverse_sigmoid_decay()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.utils.set_seeds"><code class="docutils literal notranslate"><span class="pre">set_seeds()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.utils.write_checkpoint"><code class="docutils literal notranslate"><span class="pre">write_checkpoint()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-chatbot.engine">Module contents</a><ul>
<li><a class="reference internal" href="#chatbot.engine.Evaluator"><code class="docutils literal notranslate"><span class="pre">Evaluator</span></code></a><ul>
<li><a class="reference internal" href="#chatbot.engine.Evaluator.chat"><code class="docutils literal notranslate"><span class="pre">Evaluator.chat()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.Evaluator.evaluate"><code class="docutils literal notranslate"><span class="pre">Evaluator.evaluate()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#chatbot.engine.Timer"><code class="docutils literal notranslate"><span class="pre">Timer</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul>
<li><a class="reference internal" href="#chatbot.engine.Trainer.batched_bleu_score"><code class="docutils literal notranslate"><span class="pre">Trainer.batched_bleu_score()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.Trainer.compute_metrics"><code class="docutils literal notranslate"><span class="pre">Trainer.compute_metrics()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.Trainer.train"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#chatbot.engine.set_seeds"><code class="docutils literal notranslate"><span class="pre">set_seeds()</span></code></a></li>
<li><a class="reference internal" href="#chatbot.engine.write_checkpoint"><code class="docutils literal notranslate"><span class="pre">write_checkpoint()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">chatbot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">chatbot.engine package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/chatbot.engine.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="chatbot-engine-package">
<h1>chatbot.engine package<a class="headerlink" href="#chatbot-engine-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-chatbot.engine.evaluator">
<span id="chatbot-engine-evaluator-module"></span><h2>chatbot.engine.evaluator module<a class="headerlink" href="#module-chatbot.engine.evaluator" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.evaluator.Evaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.evaluator.</span></span><span class="sig-name descname"><span class="pre">Evaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectorizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="chatbot.data.html#chatbot.data.vectorizer.SequenceVectorizer" title="chatbot.data.vectorizer.SequenceVectorizer"><span class="pre">SequenceVectorizer</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#chatbot.engine.evaluator.Evaluator" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.evaluator.Evaluator.chat">
<span class="sig-name descname"><span class="pre">chat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">searcher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.evaluator.Evaluator.chat" title="Link to this definition"></a></dt>
<dd><p>Starts an interactive conversation with the bot.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.evaluator.Evaluator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_seq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">searcher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#chatbot.engine.evaluator.Evaluator.evaluate" title="Link to this definition"></a></dt>
<dd><p>Generates a list of tokens in response to the input query
sequence.</p>
<p>Implements a forward pass through the decoder and samples its
predictions to obtain the best response tokens at each time-step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query_seq</strong> (<em>str</em>) – The input query sequence.</p></li>
<li><p><strong>searcher</strong> (<em>torch.nn.Module</em>) – A search decoder for sampling the
decoder’s predictions. Available searcher decoders:
<cite>GreedySearchSampler</cite> and <cite>RandomSearchSampler</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The generated tokens.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-chatbot.engine.trainer">
<span id="chatbot-engine-trainer-module"></span><h2>chatbot.engine.trainer module<a class="headerlink" href="#module-chatbot.engine.trainer" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.trainer.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.trainer.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="chatbot.data.html#chatbot.data.vocabulary.SequenceVocabulary" title="chatbot.data.vocabulary.SequenceVocabulary"><span class="pre">SequenceVocabulary</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_early_stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_lr_scheduler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'greedy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_lr_scheduler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ReduceLROnPlateau</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_lr_scheduler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ReduceLROnPlateau</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#chatbot.engine.trainer.Trainer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for training a sequence-to-sequence text generation model with
PyTorch.</p>
<p>The model consists of encoder and decoder layers, each trained separately
using its own optimizer.</p>
<p>Incorporates functionalities such as early stopping, resuming from
checkpoint, learning rate scheduling and MLFlow tracking.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<em>str</em>) – The file path to save or load a checkpoint.</p></li>
<li><p><strong>embedding</strong> (<em>torch.nn.Embedding</em>) – The embedding layer.</p></li>
<li><p><strong>encoder</strong> (<em>torch.nn.Module</em>) – The encoder layer.</p></li>
<li><p><strong>decoder</strong> (<em>torch.nn.Module</em>) – The decoder layer.</p></li>
<li><p><strong>encoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer for updating
the parameters of the encoder.</p></li>
<li><p><strong>decoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer for updating
the parameters of the decoder.</p></li>
<li><p><strong>loss_fn</strong> (<em>torch.nn.Model</em>) – Loss to optimize.</p></li>
<li><p><strong>vocab</strong> (<a class="reference internal" href="chatbot.data.html#chatbot.data.vocabulary.SequenceVocabulary" title="chatbot.data.vocabulary.SequenceVocabulary"><em>SequenceVocabulary</em></a>) – The dataset’s vocabulary.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of training epochs (default=5).</p></li>
<li><p><strong>clip_factor</strong> (<em>float</em><em>, </em><em>optional</em>) – Max norm value for gradient clipping.
Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>resume</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, resumes training from
the specified checkpoint. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_early_stop</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> utilizes the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">early_stopper</span></code> for stopping the training process
if the validation loss doesn’t decrease for a number of epochs.
Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_lr_scheduler</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, activates the
learning rate schedulers for the encoder and decoder. Defaults
to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>last_epoch</strong> (<em>int</em><em>, </em><em>optional</em>) – Used in case of resuming training
from the last checkpoint (default=0).</p></li>
<li><p><strong>sampling_decay</strong> (<em>int</em><em> | </em><em>float</em><em>, </em><em>optional</em>) – Decay value for the
sampling scheduler. Refer to
<a class="reference internal" href="#chatbot.engine.utils.inverse_sigmoid_decay" title="chatbot.engine.utils.inverse_sigmoid_decay"><code class="xref py py-func docutils literal notranslate"><span class="pre">chatbot.engine.utils.inverse_sigmoid_decay()</span></code></a>.</p></li>
<li><p><strong>sampling_method</strong> (<em>str</em><em>, </em><em>optional</em>) – Decoding search technique
to use for sampling the decoder’s predictions. Available
techniques: <code class="docutils literal notranslate"><span class="pre">greedy</span></code>, and <code class="docutils literal notranslate"><span class="pre">random</span></code>.</p></li>
<li><p><strong>early_stopper</strong> (<a class="reference internal" href="#chatbot.engine.utils.EarlyStopping" title="chatbot.engine.utils.EarlyStopping"><em>EarlyStopping</em></a><em>, </em><em>optional</em>) – Stops the training process
if the validation loss doesn’t decrease for a number of epochs.
Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>encoder_lr_scheduler</strong> (<em>ReduceLROnPlateau</em><em>, </em><em>optional</em>) – Reduces the
learning rate of the encoder when the validation loss stops
decreasing. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>decoder_lr_scheduler</strong> (<em>ReduceLROnPlateau</em><em>, </em><em>optional</em>) – Reduces the
learning rate of the decoder when the validation loss stops
decreasing. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.trainer.Trainer.batched_bleu_score">
<span class="sig-name descname"><span class="pre">batched_bleu_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#chatbot.engine.trainer.Trainer.batched_bleu_score" title="Link to this definition"></a></dt>
<dd><p>Calculates the BLEU-1 score between a batch of
predicted token indices and a batch of target token
indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_preds</strong> – tensor of shape <span class="math notranslate nohighlight">\((N, L)\)</span> where
<span class="math notranslate nohighlight">\(N\)</span> is the batch size and <span class="math notranslate nohighlight">\(L\)</span>
the maximum length of the sequences.</p></li>
<li><p><strong>y_targets</strong> – tensor of shape <span class="math notranslate nohighlight">\((N, L)\)</span> where
<span class="math notranslate nohighlight">\(N\)</span> is the batch size and <span class="math notranslate nohighlight">\(L\)</span>
the maximum length of the sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The BLEU-1 score.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.trainer.Trainer.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decoder_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_hidden</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_responses</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response_max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#chatbot.engine.trainer.Trainer.compute_metrics" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass through the decoder.</p>
<p>Implements a scheduled sampling mechanism which, based on
the <code class="xref py py-attr docutils literal notranslate"><span class="pre">sampling_probability</span></code>, decides whether to use
the actual target token as next input to the decoder or
an estimated token coming from the decoder’s output.</p>
<p>The estimation from the decoder is obtained by sampling a token
according to decoder’s output probability distribution over the
vocabulary.</p>
<p>For each token in the input sequence the loss and perplexity
are computed and accumulated. Also, the bleu score per batch
is calculated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder_input</strong> – tensor of shape: math:<cite>(1, N)</cite>.</p></li>
<li><p><strong>decoder_hidden</strong> – tensor of shape: math:<cite>(1, N, H)</cite>.</p></li>
<li><p><strong>encoder_state</strong> – tensor of shape: math:<cite>(L_{in}, N, H)</cite>.</p></li>
<li><p><strong>y_responses</strong> – tensor of shape: math:<cite>(L_{out}, N)</cite>.</p></li>
<li><p><strong>response_max_length</strong> – The max sequence length in a batch
of sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The loss value and the evaluation</dt><dd><p>metrics.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.trainer.Trainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tqdm_bar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tqdm</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.trainer.Trainer.train" title="Link to this definition"></a></dt>
<dd><p>Trains and validates a sequence-to-sequence text generation model
consisting of encoder and decoder layers.</p>
<dl class="simple">
<dt>The training process includes:</dt><dd><ul class="simple">
<li><p>Tracking training progress with MLFlow and custom tqdm bar</p></li>
<li><p>Checkpointing</p></li>
<li><p>Learning rate reduction</p></li>
<li><p>Early stopping</p></li>
</ul>
</dd>
</dl>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">enable_early_stop</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> a checkpoint is saved after
every epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
creating the training batch generator.</p></li>
<li><p><strong>val_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
creating the validation batch generator.</p></li>
<li><p><strong>tqdm_bar</strong> (<em>tqdm</em>) – Custom tqdm bar for the training.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-chatbot.engine.utils">
<span id="chatbot-engine-utils-module"></span><h2>chatbot.engine.utils module<a class="headerlink" href="#module-chatbot.engine.utils" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.utils.EarlyStopping">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.utils.</span></span><span class="sig-name descname"><span class="pre">EarlyStopping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'./checkpoint.pt'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#chatbot.engine.utils.EarlyStopping" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Stops the training process and checkpoints the states of
the training components of a seq-to-seq model.</p>
<p>The stopping occurs if the loss value during the validation
step stops decreasing for a number of epochs specified by
the <code class="xref py py-attr docutils literal notranslate"><span class="pre">patience</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patience</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of epochs to wait
before early stopping. (default=5).</p></li>
<li><p><strong>delta</strong> (<em>float</em><em>, </em><em>optional</em>) – Minimum change in monitored
quantity to qualify as an improvement (default=0).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, logs a message
for each improvement. Defaults to <cite>False</cite>.</p></li>
<li><p><strong>path</strong> (<em>str</em><em>, </em><em>optional</em>) – Path to write the checkpoint.
Should include either <cite>.pth</cite> or <cite>.pt</cite> as the file
extension. Defaults to <code class="docutils literal notranslate"><span class="pre">'./checkpoint.pth'</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.utils.Timer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.utils.</span></span><span class="sig-name descname"><span class="pre">Timer</span></span><a class="headerlink" href="#chatbot.engine.utils.Timer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Context manager to count elapsed time.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">do_something</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">Timer</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
<span class="gp">... </span>  <span class="n">do_something</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invocation of f took </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">elapsed</span><span class="si">}</span><span class="s2">s!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="chatbot.engine.utils.generate_batches">
<span class="sig-prename descclassname"><span class="pre">chatbot.engine.utils.</span></span><span class="sig-name descname"><span class="pre">generate_batches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#chatbot.engine.utils.generate_batches" title="Link to this definition"></a></dt>
<dd><p>Creates a batch generator from a <cite>DataLoader</cite> that
yields data dictionaries upon iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The input
dataloader.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>An iterator over</dt><dd><p>data dictionaries.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[Dict[str, torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="chatbot.engine.utils.inverse_sigmoid_decay">
<span class="sig-prename descclassname"><span class="pre">chatbot.engine.utils.</span></span><span class="sig-name descname"><span class="pre">inverse_sigmoid_decay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#chatbot.engine.utils.inverse_sigmoid_decay" title="Link to this definition"></a></dt>
<dd><p>Implements an inverse sigmoid decay scheduler.</p>
<p>The implementation is based on the paper <cite>Scheduled Sampling for
Sequence Prediction with Recurrent Neural Networks</cite>. Samy Bengio,
Oriol Vinyals, Navdeep Jaitly, Noam Shazeer.
<a class="reference external" href="https://arxiv.org/abs/1506.03099">https://arxiv.org/abs/1506.03099</a>.</p>
<p>Reduces the probability of selecting the actual target token over
the decoder’s prediction to be fed into the decoder at the next
time step.</p>
<p>The probability <span class="math notranslate nohighlight">\(e_{i}\)</span> at epoch <span class="math notranslate nohighlight">\(i\)</span> and with a
<code class="xref py py-attr docutils literal notranslate"><span class="pre">decay</span></code> value <span class="math notranslate nohighlight">\(k\)</span> is computed with the following
function:</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    e_i = \frac{k}{k + exp(\frac{i}{k})}, \text{ where } k \ge 1
\end{aligned}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decay</strong> (<em>int</em>) – The scheduled sampling decay factor.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) – Running epoch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The probability of selecting the actual target as next</dt><dd><p>input to the decoder.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="chatbot.engine.utils.set_seeds">
<span class="sig-prename descclassname"><span class="pre">chatbot.engine.utils.</span></span><span class="sig-name descname"><span class="pre">set_seeds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.utils.set_seeds" title="Link to this definition"></a></dt>
<dd><p>Sets random seeds for torch operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – Random seed to set (default=42).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="chatbot.engine.utils.write_checkpoint">
<span class="sig-prename descclassname"><span class="pre">chatbot.engine.utils.</span></span><span class="sig-name descname"><span class="pre">write_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'./checkpoint.pth'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.utils.write_checkpoint" title="Link to this definition"></a></dt>
<dd><p>Saves the states of the training components of a seq-to-seq
model and also the last validation loss and epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<em>int</em>) – Current epoch.</p></li>
<li><p><strong>embedding</strong> (<em>torch.nn.Embedding</em>) – The embedding layer.</p></li>
<li><p><strong>encoder</strong> (<em>torch.nn.Module</em>) – The encoder layer.</p></li>
<li><p><strong>decoder</strong> (<em>torch.nn.Module</em>) – The decoder layer.</p></li>
<li><p><strong>encoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer of
the encoder.</p></li>
<li><p><strong>decoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer of
the decoder.</p></li>
<li><p><strong>val_loss</strong> (<em>float</em>) – Loss value during validation.</p></li>
<li><p><strong>path</strong> (<em>str</em><em>, </em><em>optional</em>) – Path to write the checkpoint.
Should include either <cite>.pth</cite> or <cite>.pt</cite> as the file
extension. Defaults to <code class="docutils literal notranslate"><span class="pre">'./checkpoint.pth'</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-chatbot.engine">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-chatbot.engine" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.Evaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.</span></span><span class="sig-name descname"><span class="pre">Evaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectorizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="chatbot.data.html#chatbot.data.vectorizer.SequenceVectorizer" title="chatbot.data.vectorizer.SequenceVectorizer"><span class="pre">SequenceVectorizer</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#chatbot.engine.Evaluator" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.Evaluator.chat">
<span class="sig-name descname"><span class="pre">chat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">searcher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.Evaluator.chat" title="Link to this definition"></a></dt>
<dd><p>Starts an interactive conversation with the bot.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.Evaluator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_seq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">searcher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#chatbot.engine.Evaluator.evaluate" title="Link to this definition"></a></dt>
<dd><p>Generates a list of tokens in response to the input query
sequence.</p>
<p>Implements a forward pass through the decoder and samples its
predictions to obtain the best response tokens at each time-step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query_seq</strong> (<em>str</em>) – The input query sequence.</p></li>
<li><p><strong>searcher</strong> (<em>torch.nn.Module</em>) – A search decoder for sampling the
decoder’s predictions. Available searcher decoders:
<cite>GreedySearchSampler</cite> and <cite>RandomSearchSampler</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The generated tokens.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.Timer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.</span></span><span class="sig-name descname"><span class="pre">Timer</span></span><a class="headerlink" href="#chatbot.engine.Timer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Context manager to count elapsed time.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">do_something</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">Timer</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
<span class="gp">... </span>  <span class="n">do_something</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invocation of f took </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">elapsed</span><span class="si">}</span><span class="s2">s!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="chatbot.engine.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">chatbot.engine.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="chatbot.data.html#chatbot.data.vocabulary.SequenceVocabulary" title="chatbot.data.vocabulary.SequenceVocabulary"><span class="pre">SequenceVocabulary</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_early_stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_lr_scheduler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'greedy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_lr_scheduler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ReduceLROnPlateau</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_lr_scheduler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ReduceLROnPlateau</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#chatbot.engine.Trainer" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for training a sequence-to-sequence text generation model with
PyTorch.</p>
<p>The model consists of encoder and decoder layers, each trained separately
using its own optimizer.</p>
<p>Incorporates functionalities such as early stopping, resuming from
checkpoint, learning rate scheduling and MLFlow tracking.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<em>str</em>) – The file path to save or load a checkpoint.</p></li>
<li><p><strong>embedding</strong> (<em>torch.nn.Embedding</em>) – The embedding layer.</p></li>
<li><p><strong>encoder</strong> (<em>torch.nn.Module</em>) – The encoder layer.</p></li>
<li><p><strong>decoder</strong> (<em>torch.nn.Module</em>) – The decoder layer.</p></li>
<li><p><strong>encoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer for updating
the parameters of the encoder.</p></li>
<li><p><strong>decoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer for updating
the parameters of the decoder.</p></li>
<li><p><strong>loss_fn</strong> (<em>torch.nn.Model</em>) – Loss to optimize.</p></li>
<li><p><strong>vocab</strong> (<a class="reference internal" href="chatbot.data.html#chatbot.data.vocabulary.SequenceVocabulary" title="chatbot.data.vocabulary.SequenceVocabulary"><em>SequenceVocabulary</em></a>) – The dataset’s vocabulary.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of training epochs (default=5).</p></li>
<li><p><strong>clip_factor</strong> (<em>float</em><em>, </em><em>optional</em>) – Max norm value for gradient clipping.
Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>resume</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, resumes training from
the specified checkpoint. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_early_stop</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> utilizes the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">early_stopper</span></code> for stopping the training process
if the validation loss doesn’t decrease for a number of epochs.
Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>enable_lr_scheduler</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, activates the
learning rate schedulers for the encoder and decoder. Defaults
to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>last_epoch</strong> (<em>int</em><em>, </em><em>optional</em>) – Used in case of resuming training
from the last checkpoint (default=0).</p></li>
<li><p><strong>sampling_decay</strong> (<em>int</em><em> | </em><em>float</em><em>, </em><em>optional</em>) – Decay value for the
sampling scheduler. Refer to
<a class="reference internal" href="#chatbot.engine.utils.inverse_sigmoid_decay" title="chatbot.engine.utils.inverse_sigmoid_decay"><code class="xref py py-func docutils literal notranslate"><span class="pre">chatbot.engine.utils.inverse_sigmoid_decay()</span></code></a>.</p></li>
<li><p><strong>sampling_method</strong> (<em>str</em><em>, </em><em>optional</em>) – Decoding search technique
to use for sampling the decoder’s predictions. Available
techniques: <code class="docutils literal notranslate"><span class="pre">greedy</span></code>, and <code class="docutils literal notranslate"><span class="pre">random</span></code>.</p></li>
<li><p><strong>early_stopper</strong> (<a class="reference internal" href="#chatbot.engine.utils.EarlyStopping" title="chatbot.engine.utils.EarlyStopping"><em>EarlyStopping</em></a><em>, </em><em>optional</em>) – Stops the training process
if the validation loss doesn’t decrease for a number of epochs.
Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>encoder_lr_scheduler</strong> (<em>ReduceLROnPlateau</em><em>, </em><em>optional</em>) – Reduces the
learning rate of the encoder when the validation loss stops
decreasing. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>decoder_lr_scheduler</strong> (<em>ReduceLROnPlateau</em><em>, </em><em>optional</em>) – Reduces the
learning rate of the decoder when the validation loss stops
decreasing. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.Trainer.batched_bleu_score">
<span class="sig-name descname"><span class="pre">batched_bleu_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#chatbot.engine.Trainer.batched_bleu_score" title="Link to this definition"></a></dt>
<dd><p>Calculates the BLEU-1 score between a batch of
predicted token indices and a batch of target token
indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_preds</strong> – tensor of shape <span class="math notranslate nohighlight">\((N, L)\)</span> where
<span class="math notranslate nohighlight">\(N\)</span> is the batch size and <span class="math notranslate nohighlight">\(L\)</span>
the maximum length of the sequences.</p></li>
<li><p><strong>y_targets</strong> – tensor of shape <span class="math notranslate nohighlight">\((N, L)\)</span> where
<span class="math notranslate nohighlight">\(N\)</span> is the batch size and <span class="math notranslate nohighlight">\(L\)</span>
the maximum length of the sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The BLEU-1 score.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.Trainer.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decoder_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_hidden</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_responses</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response_max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#chatbot.engine.Trainer.compute_metrics" title="Link to this definition"></a></dt>
<dd><p>Performs a forward pass through the decoder.</p>
<p>Implements a scheduled sampling mechanism which, based on
the <code class="xref py py-attr docutils literal notranslate"><span class="pre">sampling_probability</span></code>, decides whether to use
the actual target token as next input to the decoder or
an estimated token coming from the decoder’s output.</p>
<p>The estimation from the decoder is obtained by sampling a token
according to decoder’s output probability distribution over the
vocabulary.</p>
<p>For each token in the input sequence the loss and perplexity
are computed and accumulated. Also, the bleu score per batch
is calculated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder_input</strong> – tensor of shape: math:<cite>(1, N)</cite>.</p></li>
<li><p><strong>decoder_hidden</strong> – tensor of shape: math:<cite>(1, N, H)</cite>.</p></li>
<li><p><strong>encoder_state</strong> – tensor of shape: math:<cite>(L_{in}, N, H)</cite>.</p></li>
<li><p><strong>y_responses</strong> – tensor of shape: math:<cite>(L_{out}, N)</cite>.</p></li>
<li><p><strong>response_max_length</strong> – The max sequence length in a batch
of sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The loss value and the evaluation</dt><dd><p>metrics.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="chatbot.engine.Trainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tqdm_bar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tqdm</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.Trainer.train" title="Link to this definition"></a></dt>
<dd><p>Trains and validates a sequence-to-sequence text generation model
consisting of encoder and decoder layers.</p>
<dl class="simple">
<dt>The training process includes:</dt><dd><ul class="simple">
<li><p>Tracking training progress with MLFlow and custom tqdm bar</p></li>
<li><p>Checkpointing</p></li>
<li><p>Learning rate reduction</p></li>
<li><p>Early stopping</p></li>
</ul>
</dd>
</dl>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">enable_early_stop</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> a checkpoint is saved after
every epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
creating the training batch generator.</p></li>
<li><p><strong>val_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
creating the validation batch generator.</p></li>
<li><p><strong>tqdm_bar</strong> (<em>tqdm</em>) – Custom tqdm bar for the training.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="chatbot.engine.set_seeds">
<span class="sig-prename descclassname"><span class="pre">chatbot.engine.</span></span><span class="sig-name descname"><span class="pre">set_seeds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.set_seeds" title="Link to this definition"></a></dt>
<dd><p>Sets random seeds for torch operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – Random seed to set (default=42).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="chatbot.engine.write_checkpoint">
<span class="sig-prename descclassname"><span class="pre">chatbot.engine.</span></span><span class="sig-name descname"><span class="pre">write_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'./checkpoint.pth'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#chatbot.engine.write_checkpoint" title="Link to this definition"></a></dt>
<dd><p>Saves the states of the training components of a seq-to-seq
model and also the last validation loss and epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<em>int</em>) – Current epoch.</p></li>
<li><p><strong>embedding</strong> (<em>torch.nn.Embedding</em>) – The embedding layer.</p></li>
<li><p><strong>encoder</strong> (<em>torch.nn.Module</em>) – The encoder layer.</p></li>
<li><p><strong>decoder</strong> (<em>torch.nn.Module</em>) – The decoder layer.</p></li>
<li><p><strong>encoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer of
the encoder.</p></li>
<li><p><strong>decoder_optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer of
the decoder.</p></li>
<li><p><strong>val_loss</strong> (<em>float</em>) – Loss value during validation.</p></li>
<li><p><strong>path</strong> (<em>str</em><em>, </em><em>optional</em>) – Path to write the checkpoint.
Should include either <cite>.pth</cite> or <cite>.pt</cite> as the file
extension. Defaults to <code class="docutils literal notranslate"><span class="pre">'./checkpoint.pth'</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Kanaris Konstantinos.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>